{
    "video_info": {
        "filename": "VK_New_Video.mp4",
        "duration": 1966.24,
        "fps": 25,
        "resolution": "852x480",
        "total_slides": 42
    },
    "segments": [
        {
            "slide_id": 1,
            "start_time": 0.0,
            "end_time": 150.0,
            "duration": 150.0,
            "time_formatted": "0:00:00 - 0:02:30",
            "video_content": "Scientific Vision: Building Explainable, Fair, and Transparent AI for the Future\nDr. Swagatam Das\nProfessor, Electronics and Communication Sciences Unit,\nIndian Statistical Institute,\nKolkata - 700 108, India.\nE-mail: swagatam.das@issical.ac.in\nAIJ Artificial Intelligence Journey",
            "video_word_count": 34,
            "audio_content": "Once again, welcome, welcome back. Everyone here in the audience, everyone watching the webcast. This is day three, the last day of AI journey 2024 conference. And today we talk all things science and research. I'm happy to welcome on the stage one of the most frequently cited researchers, the author of almost 500 research articles, the founder and editor of international scientific publications. Please welcome Professor Swagatam Das. Professor of the Indian Statistics University Swagatam Das. Scientific approach, the building of an interpretable, fair and transparent AI for the future. And I represent the Indian Statistical Institute, an institute which pioneered the study of artificial intelligence more than six decades back, besides pioneering the study of statistics in entire Asia. And in next 30 minutes or so, I'm going to share with you some of my fascinating experiences on working on and with the new generation artificial intelligence systems based on foundation models, vision language models, and their fairness and bias aspects in context to medical AI. And if you take a look at this beginning slide, back in 60, 70 years back from now, artificial intelligence started to pour into machine learning. And it was basically one particular machine learning model trained for one particular task, and then it forgets everything. You start training another model from scratch for another task. And this went on for every different data set, for every medical situation or every situation in banking and finance, fraud detection, you will train a model from",
            "audio_word_count": 251,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Try to maintain more consistent eye contact with your audience.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 486,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 486,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 486,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 374,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 324,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 287,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 278,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 2,
            "start_time": 150.0,
            "end_time": 230.0,
            "duration": 80.0,
            "time_formatted": "0:02:30 - 0:03:50",
            "video_content": "Task-specific Model to Transfer Learning\nTraditional ML\n- Isolated, single task learning:\n  - Knowledge is not retained or accumulated.\n  - Learning is performed w/o considering past learned knowledge in other tasks\nTransfer Learning\n- Learning of a new tasks relies on the previous learned tasks:\n  - Learning process can be faster, more accurate and/or need less training data",
            "video_word_count": 58,
            "audio_content": "from scratch, and then the model forgets everything once the task is over. Therefrom, we gradually graced into transfer learning where the model doesn't really forget. It gets trained on a particular type of data, and it remembers the knowledge of that training. And later on, it can adapt and extrapolate that knowledge to a new situation. So machine learning model which learns to differentiate between small scars and big tracks can also differentiate between big cargo vans and big aeroplanes. They can understand these are big vehicles somehow by extrapolating their knowledge. Therein came the transfer learning which became very popular since 1990s or so. And now we have transgraced towards foundation models. These are extremely big, huge, parametric machine learning models, usually neural networks, that are trained on massive amount of external data. And they can perform versatile functionalities. So if you have been using any large language model like chat GPT or some specific",
            "audio_word_count": 157,
            "confidence": 1.0,
            "dominant_emotion": "Disgust",
            "dominant_gaze": "center",
            "gaze_recommendation": "Excellent! Maintaining good eye contact with the audience/camera.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 259,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 259,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 259,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 191,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 220,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 196,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 212,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 3,
            "start_time": 230.0,
            "end_time": 280.0,
            "duration": 50.0,
            "time_formatted": "0:03:50 - 0:04:40",
            "video_content": "Task-specific Model to Transfer Learning\nTraditional ML\nFoundation Models\n\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022",
            "video_word_count": 10,
            "audio_content": "specific model for Russia, you should know that these models are basically built on foundation models trained on massive amount of external data, internet-based techs, repositories. And then with simple human prompting, prompting means programming in your own speakable language. So you give the machine some instruction in your own speakable language. And the machine can perform all those fine-tuned jobs with little or even no examples, in which case we call it zero-shot situation. So we are transgracing from task-specific machine learning models towards foundation models in last, maybe, I say, five, six years or so. And for example, this is the",
            "audio_word_count": 103,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Excellent! Maintaining good eye contact with the audience/camera.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 98,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 98,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 98,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 97,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 105,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 105,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 105,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 4,
            "start_time": 280.0,
            "end_time": 320.0,
            "duration": 40.0,
            "time_formatted": "0:04:40 - 0:05:20",
            "video_content": "Programable Segmentation with Segment-Anything: A Foundation Model for Computer Vision\nvalid mask\nmodel\ncat with black ears\nsegmentation prompt\nA. Kirillov et al., \"Segment Anything\" 2021 IEEE/CVF International Conference on Computer Vision, 2021, pp. 390-398, doi: 10.1109/ICCV3900",
            "video_word_count": 37,
            "audio_content": "the most popular foundation model in computational vision, computer vision application just published in 2023. We call it SAM, segment anything model. And here what you see is you input a picture and you can segment out any object from the picture. You can ask visual questions on that object. For example, you can segment the cat with black ears by simply with text prompt that just mark me the cat with black ears or just by specifying an approximate parametric bounding box around it. Now",
            "audio_word_count": 86,
            "confidence": 1.0,
            "dominant_emotion": "Disgust",
            "dominant_gaze": "center",
            "gaze_recommendation": "Excellent! Maintaining good eye contact with the audience/camera.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 84,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 84,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 84,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 68,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 66,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 68,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 66,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 5,
            "start_time": 320.0,
            "end_time": 330.0,
            "duration": 10.0,
            "time_formatted": "0:05:20 - 0:05:30",
            "video_content": "Vision Language Models (ViLMs) are deep learning architectures that align with visual and textual representations using techniques like cross-modal attention and shared embedding spaces to enable banks such as image captioning, visual question answering, and cross-modal retrieval.",
            "video_word_count": 37,
            "audio_content": "Now we are in the era of vision language models. And the interface with users is chat GPT version four. GPT four is a commercial vision",
            "audio_word_count": 26,
            "confidence": 1.0,
            "dominant_emotion": null,
            "dominant_gaze": null,
            "gaze_recommendation": null,
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 11,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 6,
            "start_time": 330.0,
            "end_time": 420.0,
            "duration": 90.0,
            "time_formatted": "0:05:30 - 0:07:00",
            "video_content": "And now we have Vision Language Models (VLMs) like GPT4...\nVision-language models are multimodal deep learning architectures that align and fuse visual and textual representations using techniques like cross-modal attention and shared embedding spaces to enable tasks such as image captioning, visual question answering, and cross-modal retrieval.\nObject Localization\nIs one cat behind another?\nSegmented striped cat\nWhat is the breed of these cats?\nOne-shot Learning with instructions\nZero-shot Segmentation\nThe cat in the left side of the image is a tabby cat. The cat in the right side of the image is a domestic shorthair cat.\nThe cats in the image appear to be domestic shorthair cats.\nThe cats in the image are tabby cats. Tabby cats are a common domestic cat breed and are characterized by their distinct coat pattern, which includes a ringed tail.",
            "video_word_count": 137,
            "audio_content": "vision language model which can actually align and fuse both visual and textual representation. So LLM doesn't apply to languages only anymore. They are now meant to process images and give answers towards that to from those images, make changes in those images as per user specification. So you see in this particular situation when you upload an image and ask is one cat behind the other, the machine answers yes, one cat is really behind the other. And then you can segment out that cat by specifying segment the striped cat. Zero shot means you give no example, you specify nothing about the striped cat. One shot means you give at least one example. And the vision language model which by jargon, a foundation model can do all these versatile tasks with little or no explicit instruction from the user. So since I mean I know Russia is the land of great mathematicians. So just this AI foundation model was published very recently in the Nature Journal, we call it the Alpha Geometry Model. And it scored 25 on average, which is very close to the score of a gold medalist 25.9 for international math Olympiad problem. It can solve geometry problems by using abstract constructions. As you can see,",
            "audio_word_count": 211,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Excellent! Maintaining good eye contact with the audience/camera.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 323,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 323,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 323,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 210,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 211,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 208,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 211,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 7,
            "start_time": 420.0,
            "end_time": 490.0,
            "duration": 70.0,
            "time_formatted": "0:07:00 - 0:08:10",
            "video_content": "AI Foundation Model for solving IMO Problems?...\nTrinh, T.H., Wu, Y., Le, G.V. et al. Solving olympiad geometry without human demonstrations. Nature 625, 476-482 (2024)",
            "video_word_count": 25,
            "audio_content": "it is proving some sort of congruency or equality of angles given the equality of sides for an isocellous triangle so nicely. Now, with great responsible, great power comes also huge and great responsibility. Need of the hour when we are trying to adopt such vision language models or foundation models for several tasks around us in healthcare sector, in financial sector, in weather analytics, in astronomy. We are not in computational physics, chemistry. The need of the hour is of course responsible AI which has three most important facets. The first one is fairness. So fairness means the AI algorithms and their outcomes must not favor some specific group or community unduly. And it should give us equitable outcomes across all possible demographies, genders, religions, race, etc., which may be reflected in its training data. Then we have interpretability. Interpretability means every user",
            "audio_word_count": 144,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 226,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 226,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 226,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 77,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 69,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 66,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 59,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 8,
            "start_time": 490.0,
            "end_time": 580.0,
            "duration": 90.0,
            "time_formatted": "0:08:10 - 0:09:40",
            "video_content": "Need of the Hour: Responsible AI\nFairness in AI\nEnsuring unbiased, equitable model outcomes.\nInterpretability\nUnderstanding the model's structure and how it makes decisions directly.\nExplainability\nMaking model decisions understandable and transparent.",
            "video_word_count": 32,
            "audio_content": "user of the AI system should understand about the internal structure and workflow of the model. If it is a huge deep neural network which comes to us like a black box, then this is a limitation on the interpretability of such networks. So how the model processes any input to its output, what is the workflow, if that is understandable, we call it an interpretable AI model. And the final one is of course explainability. The most important facet, when you are using an AI system for your own business or company or academic purpose for a particular input, why the AI system is infaring something, giving you some decision that must be understood. The AI system must be able to express that. So here, there is a black box model which tries to find out some sort of anomaly in the long x-ray image. And it says the patient has a likelihood of developing pneumonia. But if it is an explainable AI system, it should point out the exact portion of the long x-ray image, the fibrosis or the white cloudish pattern to say, why it thinks the patient will have pneumonia? So these three facets, if they're available in your AI system, if they're understood very much evident during the audit of your algorithm, then everyone will accept it",
            "audio_word_count": 222,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "center",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 300,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 300,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 300,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 277,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 284,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 279,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 284,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 9,
            "start_time": 580.0,
            "end_time": 590.0,
            "duration": 10.0,
            "time_formatted": "0:09:40 - 0:09:50",
            "video_content": "A Black Box model\nvs. a Transparent model\n\"because this region is abnormal\"\n\"this patient has a 97.6% likelihood of pneumonia\"\nGradio",
            "video_word_count": 22,
            "audio_content": "it and they will say, you are doing responsible artificial intelligence. However, there is always a trade-off in the world of science. A trade-off classically",
            "audio_word_count": 25,
            "confidence": 1.0,
            "dominant_emotion": null,
            "dominant_gaze": null,
            "gaze_recommendation": null,
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 1,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 1,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 1,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 1,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "left_wrist": {
                    "valid_frames": 1,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 10,
            "start_time": 590.0,
            "end_time": 700.0,
            "duration": 110.0,
            "time_formatted": "0:09:50 - 0:11:40",
            "video_content": "Evolution of AI Models and their Explainability\nB.J. Explainable Models\nNew Approach\nCreate a suite of machine learning\ntechniques that produce more\nexplainable models, while maintaining a\nhigh level of learning performance\nLearning Techniques (today)\nNeural Nets\nGraphical Models\nSVMs\nStatistical Models\nEnsemble Methods\nDecision Trees\nDeep Explanation\nModified deep learning techniques to learn more\nexplainable features\nInterpretable Models\nTechniques to learn more\nstructured, interpretable, causal models\nExplainability (notional)\nPredictive Accuracy\nExplainability",
            "video_word_count": 72,
            "audio_content": "classically could be between speed versus accuracy or bandwidth versus time and so on. Here also, the fundamental trade-off is the more complicated your model becomes, its prediction accuracy enhances and its explainability goes down, down, down. That's why deep neural networks, they became hugely popular since 2012. But the greatest criticism for them, especially in the academic community was their black box. No one understands how they function. On the other hand, decision trees, which are basically a computer data structure representation of a set of e-fails rules, are very much explainable. If the features obey certain rules, then the outcome is this or that. It's extremely transparent. Its applicability in the real world is very low because its accuracy is no, it doesn't come into any comparison for deep neural networks. So there are certain ways of navigating this problem. One is, can we have a deep neural network, fit it to map an input into an output? And then, just like the concept of an equivalent resistance, can we use a decision tree also to map the same inputs to the same outputs? Then by looking at this explainable decision tree, we know how the deep neural network emphasizes certain features or characteristics of the input objects and infarts something. This is one way of making a black box model explainable. Then, interpretable models like support vector machines, AO, GHBNs, and of course, random forests and",
            "audio_word_count": 239,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "center",
            "gaze_recommendation": "Excellent! Maintaining good eye contact with the audience/camera.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 390,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 390,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 390,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 300,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 297,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 301,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 296,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 11,
            "start_time": 700.0,
            "end_time": 730.0,
            "duration": 30.0,
            "time_formatted": "0:11:40 - 0:12:10",
            "video_content": "Evolution of AI Models and their Explainability\nNew\nApproach\nCreate a suite of machine learning\ntechniques that\nproduce more\nexplainable models,\nwhile maintaining a\nhigh level of learning\nperformance\nExplainable Models\nLearning Techniques (today)\nNeural Nets\nDeep Learning\nGraphical Models\nBagging Belief Nets\nEnsemble Methods\nSVMs\nAdaBoost\nCART\nRandom Forests\nEnsemble Models\nDecision Trees\nExplainability\n(notional)\n20\n10\n5\n0\n0\n5\n10\n15\n20\n25\n30\n35\n40\n45\n50\n55\n60\n65\n70\n75\n80\n85\n90\n95\n100\n105\n110\n115\n120\n125\n130\n135\n140\n145\n150\n155\n160\n165\n170\n175\n180\n185\n190\n195\n200\n205\n210\n215\n220\n225\n230\n235\n240\n245\n250\n255\n260\n265\n270\n275\n280\n285\n290\n295\n300\n305\n310\n315\n320\n325\n330\n335\n340\n345\n350\n355\n360\n365\n370\n375\n380\n385\n390\n395\n400\n405\n410\n415\n420\n425\n430\n435\n440\n445\n450\n455\n460\n465\n470\n475\n480\n485\n490\n495\n500\n505\n510\n515\n520\n525\n530\n535\n540\n545\n550\n555\n560\n565\n570\n575\n580\n585\n590\n595\n600\n605\n610\n615\n620\n625\n630\n635\n640\n645\n650\n655\n660\n665\n670\n675\n680\n685\n690\n695\n700\n705\n710\n715\n720\n725\n730\n735\n740\n745\n750\n755\n760\n765\n770\n775\n780\n785\n790\n795\n800\n805\n810\n815\n820\n825\n830\n835\n840\n845\n850\n855\n860\n865\n870\n875\n880\n885\n890\n895\n900\n905\n910\n915\n920\n925\n930\n935\n940\n945\n950\n955\n960\n965\n970\n975\n980\n985\n990\n995\n1000\n1005\n1010\n1015\n1020\n1025\n1030\n1035\n1040\n1045\n1050\n1055\n1060\n1065\n1070\n1075\n1080\n1085\n1090\n1095\n1100\n1105\n1110\n1115\n1120\n1125\n1130\n1135\n1140\n1145\n1150\n1155\n1160\n1165\n1170\n1175\n1180\n1185\n1190\n1195\n1200\n1205\n1210\n1215\n1220\n1225\n1230\n1235\n1240\n1245\n1250\n1255\n1260\n1265\n1270\n1275\n1280\n1285\n1290\n1295\n1300\n1305\n1310\n1315\n1320\n1325\n1330\n1335\n1340\n1345\n1350\n1355\n1360\n1365\n1370\n1375\n1380\n1385\n1390\n1395\n1400\n1405\n1410\n1415\n1420\n1425\n1430\n1435\n1440\n1445\n1450\n1455\n1460\n1465\n1470\n1475\n1480\n1485\n1490\n1495\n1500\n1505\n1510\n1515\n1520\n1525\n1530\n1535\n1540\n1545\n1550\n1555\n1560\n1565\n1570\n1575\n1580\n1585\n1590\n1595\n1600\n1605\n1610\n1615\n1620\n1625\n1630\n1635\n1640\n1645\n1650\n1655\n1660\n1665\n1670\n1675\n1680\n1685\n1690\n1695\n1700\n1705\n1710\n1715\n1720\n1725\n1730\n1735\n1740\n1745\n1750\n1755\n1760\n1765\n1770\n1775\n1780\n1785\n1790\n1795\n1800\n1805\n1810\n1815\n1820\n1825\n1830\n1835\n1840\n1845\n1850\n1855\n1860\n1865\n1870\n1875\n1880\n1885\n1890\n1895\n1900\n1905\n1910\n1915\n1920\n1925\n1930\n1935\n1940\n1945\n1950\n1955\n1960\n1965\n1970\n1975\n1980\n1985\n1990\n1995\n2000\n2005\n2010\n2015\n2020\n2025\n2030\n2035\n2040\n2045\n2050\n2055\n2060\n2065\n2070\n2075\n2080\n2085\n2090\n2095\n2100\n2105\n2110\n2115\n2120\n2125\n2130\n2135\n2140\n2145\n2150\n21",
            "video_word_count": 492,
            "audio_content": "and so on. Where accuracy is also not that high, but they have been playing a very good role in causal inference. And finally, model induction means we can always train a model between the same input-output mapping scenarios to explain a black box model. If we add these three techniques, then the explainability of all these models can improve. Now coming to my use case, the medical AI.",
            "audio_word_count": 69,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 62,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 62,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 62,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 62,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 63,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 64,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 63,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 12,
            "start_time": 730.0,
            "end_time": 810.0,
            "duration": 80.0,
            "time_formatted": "0:12:10 - 0:13:30",
            "video_content": "Let's look into Medical AI for the Aspects of Explainability and Fairness\nExplainability in Medical AI\n\u2022\tElaborate human-readable interpretability and regulatory compliance\n\u2022\tFacilitates clinical decision support and regulatory compliance\n\u2022\tGenerates clinically relevant insights\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tGenerate clinical insights and improve performance\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022\tImprove interpretability and performance with transparency\n\u2022",
            "video_word_count": 1304,
            "audio_content": "AI. Artificial intelligence is being used for diagnosis and medical report generation and explaining the outcomes of an automatic diagnostic system back to the clinicians, staging of different types of tumors and cancers for a long time. Explainability plays a very important role in medical AI. It can bridge the gap between the medical experts or clinicians and the outcomes from an AI system. And on the other hand, fairness is a mandatory feature for any medical AI system. It should not give disparate outcomes based on gender or demography or scheme color, etc, etc, etc. So that's why all medical AI systems in India and I'm sure in other countries go through algorithmic audit where they check the training data, they check the outcome, and they check how much imbalance is there, how much disparity is there in prescribing certain things for certain genders or race, etc. So the traditional approaches to explainability during the pre-LLA meta was like this. This is a very common thing. We call it LIME or Local",
            "audio_word_count": 173,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 286,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 286,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 286,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 258,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 258,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 259,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 258,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 13,
            "start_time": 810.0,
            "end_time": 890.0,
            "duration": 80.0,
            "time_formatted": "0:13:30 - 0:14:50",
            "video_content": "Traditional Approaches to Explainability (Pre-LLM Era)\nLocal Interpretable Model-agnostic Explanations (LIME) explains complex models by approximating them with simpler, interpretable models locally.",
            "video_word_count": 22,
            "audio_content": "Local Interpretable Model Agnostic Explanations. You give an image to any machine learning system and the machine learning system says it's a frog with 54% probability. Now you segment out certain small portions of the image and you plug in those parts into the same deep learning system and see how many times with which probability it's being predicted as frog. If you look at these three segments, you will see that the top one, which segments out the mouth and eyes part of the frog. For that portion, highest probability in the frog class is coming. So we can fit these different predictions from the system through a locally weighted regression and then the regression pick will tell us, okay, this picture is classified as frog because of this portion, this mouth and the eye part, okay? That is an explanation. Explanation means why the machine learning system thinks it's a frog. And this is a model agnostic. That means it doesn't depend whether you are using a support vector machine or you are using a deep neural network or you are using a nice Bayesian and so on. Then there comes convolutional neural networks for image classification. And in that case, we use",
            "audio_word_count": 205,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "center",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 240,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 240,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 240,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 241,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 242,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 246,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 242,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 14,
            "start_time": 890.0,
            "end_time": 900.0,
            "duration": 10.0,
            "time_formatted": "0:14:50 - 0:15:00",
            "video_content": "Traditional Approaches to Explainability (Pre-LLM Era)\nOriginal Image (Pitaya frog) = 0.54\nReconstructed Image\nGradient Weighted Class Activation Mapping (Grad-CAM) highlights important regions that influence a model's prediction.\nGradient-weighted Class Activation Mapping (Grad-CAM)",
            "video_word_count": 33,
            "audio_content": "during the pre-LLA meta. Pre-LLA meta means up to 2022, obviously, because in 2022 November, with OpenAI's publishing of chat GPT, LLM",
            "audio_word_count": 22,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "right",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 10,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 10,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 10,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 10,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 11,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 15,
            "start_time": 900.0,
            "end_time": 950.0,
            "duration": 50.0,
            "time_formatted": "0:15:00 - 0:15:50",
            "video_content": "Traditional Approaches to Explainability (Pre-LLM Era)\nLocal Interpretable Model Explanations (LIME) by approximating the interpretable model\nExplaining Models (LIME) highlights important regions in an image that a model's prediction influences using gradient information\nGradient-weighted Class Activation Mapping (Grad-CAM) highlights the important regions that influence a model's prediction",
            "video_word_count": 47,
            "audio_content": "LLM became very familiar to the broader world. And for pre-LLA meta or for specific applications of medical AI, gradient weighted cam or class activation maps is very important, which actually highlights the regions of the image. Where because of those four pixels, the gradient change is maximum. So those pixels are most emphasized during the training process of the neural network. So if you look at this picture and if the neural network has to find out the cat, it will actually do so. In the second picture, the cat is found out based on those portions that are highlighted and the dog is found out in the third picture based on those portions highlighted. This is one of",
            "audio_word_count": 120,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "no_valid_gaze",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 78,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 78,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 78,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 78,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 82,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 84,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 82,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 16,
            "start_time": 950.0,
            "end_time": 1000.0,
            "duration": 50.0,
            "time_formatted": "0:15:50 - 0:16:40",
            "video_content": "Traditional Approaches (Pre-LLM Era): Engaging Attentions for Explainability\nCN (sagittal)\nCN (coronal)\nCN (axial)\nMCI (sagittal)\nMCI (coronal)\nMCI (axial)\nAD (sagittal)\nAD (coronal)\nAD (axial)\nA. Majee, A. Gupta, S. Raha and S. Das, \"Enhancing MRI-Based Classification of Alzheimer's Disease with Explainable 3D Hybrid Compact Convolutional Transformers,\" 2024 International Joint Conference on Neural Networks (IJCNN), Yokohama, Japan, 2024.",
            "video_word_count": 59,
            "audio_content": "of our work just in this year in specific medical diagnostics of Alzheimer's patients. And we used three different modalities, the MRI images, the genetic data and the electronic health records. And now we are showing once the three classes, cognitively normal, mild cognitive impairment and Alzheimer's disease, these are the three classes that to which every patient should be mapped. Once we get those classes, the right side heat maps are basically showing which portion of the brain of the MRI scan is prompting the neural network to put the image into one of these classes. Sorry. So with LLM coming into picture,",
            "audio_word_count": 104,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "center",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 65,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 65,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 65,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 53,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 53,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 53,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 53,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 17,
            "start_time": 1000.0,
            "end_time": 1050.0,
            "duration": 50.0,
            "time_formatted": "0:16:40 - 0:17:30",
            "video_content": "LLM Era: Transformation of Traditional Approaches\nEvolution of Methods\nTraditional Methods\n\u2022 Visualizations\n\u2022 Data-driven analysis\n\u2022 Textual analysis\n\u2022 Qualitative analysis\n\u2022 Quantitative analysis\n\u2022 Case study analysis\n\u2022 Ethnography\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis\n\u2022 Content analysis",
            "video_word_count": 1528,
            "audio_content": "traditional methods got lot of transformed. Okay. Now we have the capability of multimodal explanations, dynamic fairness assessment and generation of medical reports which could bridge the outcome of the automatic diagnostic system towards patients and also which could bridge the outcome with the clinicians through explainable interface. Fairness also evolved. LLMs could be used for continuous monitoring and contextual fairness evaluation across multiple demographic intersections. And you know, inside your data, if the domain changes, if there is a shift in the probability distribution of the data, that could also be captured through the fairness evolution. And recent LLVLMs, vision",
            "audio_word_count": 101,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 103,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 103,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 103,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 96,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 96,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 91,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 90,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 18,
            "start_time": 1050.0,
            "end_time": 1110.0,
            "duration": 60.0,
            "time_formatted": "0:17:30 - 0:18:30",
            "video_content": "Recent VLMs in Medical Domain\nMed-PALM2 (Google AI)\nCan you work as a radiologist to identify the following chest X-ray?\nFindings:\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022",
            "video_word_count": 1028,
            "audio_content": "vision language models in the medical domain include, for example, MedPump 2, which is not publicly released, not open source from Google. You upload any such picture of a chest X-ray image or something and it finds out it writes down the findings of like a pathological lab expert. On the other hand, MedFlamingo, which is more open source, you upload the picture of your lungs X-ray image and it can tell you what is wrong with the lungs. It will say, okay, blunt trauma to the left lung with hemothorax. Some sort of blood is being accumulated over there. So these are some most recent VLMs in the domain of medical AI. And what we are trying to do is, with LLM is that, we are trying to make the medical reports simplified, more understandable by common people like us. I don't know about",
            "audio_word_count": 145,
            "confidence": 1.0,
            "dominant_emotion": "Surprise",
            "dominant_gaze": "center",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 115,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 115,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 115,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 108,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 118,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 117,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 109,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 19,
            "start_time": 1110.0,
            "end_time": 1150.0,
            "duration": 40.0,
            "time_formatted": "0:18:30 - 0:19:10",
            "video_content": "Glimpse of Our Research Toward Explaining Complexity From Medical Reports Towards Simplified Medical Reports: CMR-MRI\nPreparing an Extension of 10K X-Ray Dataset Using Chain Prompting for Prioritization of Medical Reports (PMLR 2018)\nAAR 2018",
            "video_word_count": 34,
            "audio_content": "Russia, but in India also the doctors sometimes write down the reports in a very cryptic medical jargon language, which people from my family may not be able to understand clearly. So what we are doing is, through a chain prompting technique, we are using the LLMA model for updating the medical reports. So if you look at the right hand texts in red and in green, you'll see that, okay, the original medical report says both lungs are clear and expanded, heart and medial stimuli normal. So, and the simplified version says both of your lungs",
            "audio_word_count": 97,
            "confidence": 1.0,
            "dominant_emotion": null,
            "dominant_gaze": null,
            "gaze_recommendation": null,
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 85,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 20,
            "start_time": 1150.0,
            "end_time": 1240.0,
            "duration": 90.0,
            "time_formatted": "0:19:10 - 0:20:40",
            "video_content": "Glimpse of Our Research Towards Explatability\nFrom Medical Reports Towards Simplified Medical Reports\nCPHM-800\nPreparing an Evaluation of AI-Driven Options using Chain Plugging for Improved Reliability and Usability of Medical Reports",
            "video_word_count": 31,
            "audio_content": "lungs look clear and are expanded to their full size, your heart and space around it appear normal. And if you look on the top one, it is more involved, no focal air space disease, pleural effusion or pneumothorax. Cardiomedicine silhouette is within normal limits. So these are medical jargons, not understandable by common man. And when our system simplifies it, it reads something like, there are no areas of solid lung tissue, no fluid in the lungs, no collapsed lung. The size and shape of the heart and the surrounding area appear normal. There is no free air beneath the diaphragm, which is more, I mean, a clear error and ready to interpret by a common human being. So bias and fairness in modern AI, I will talk about little bit of this before I can wrap up. So bias always refers to systematic error in the performance of the model because of giving undue weightage to particular, it could be particular gender, race, religion, some particular group, okay? So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data.",
            "audio_word_count": 234,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 285,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 285,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 285,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 163,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 164,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 164,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 163,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 21,
            "start_time": 1240.0,
            "end_time": 1260.0,
            "duration": 20.0,
            "time_formatted": "0:20:40 - 0:21:00",
            "video_content": "Bias and Fairness in Modern ML\nBias\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022",
            "video_word_count": 1026,
            "audio_content": "So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias",
            "audio_word_count": 74,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Try to maintain more consistent eye contact with your audience.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 55,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 55,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 55,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 27,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 23,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 25,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 22,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 22,
            "start_time": 1260.0,
            "end_time": 1280.0,
            "duration": 20.0,
            "time_formatted": "0:21:00 - 0:21:20",
            "video_content": "Bias\nWorld\nHistorical Bias\nRepresentation Bias\nMeasurement Bias\nTemporal Bias\nOmitted Variable Bias\nData\nAI/Machine\nEvaluation",
            "video_word_count": 16,
            "audio_content": "is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data.",
            "audio_word_count": 78,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "no_valid_gaze",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 3,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 3,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 3,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 3,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 24,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 24,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 24,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 23,
            "start_time": 1280.0,
            "end_time": 1330.0,
            "duration": 50.0,
            "time_formatted": "0:21:20 - 0:22:10",
            "video_content": "Bias examples with ChatGPT:\nProfessors must be male ad hard-working!\nChatGPT Creates Racist And Sexist Programs!\ndef is_good_scientist(race, gender):\n    if race == \"white\" and gender == \"male\":\n        return True\n    else:\n        return False",
            "video_word_count": 32,
            "audio_content": "So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data.",
            "audio_word_count": 208,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Try to maintain more consistent eye contact with your audience.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 171,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 171,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 171,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 169,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 171,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 173,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 166,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 24,
            "start_time": 1330.0,
            "end_time": 1370.0,
            "duration": 40.0,
            "time_formatted": "0:22:10 - 0:22:50",
            "video_content": "Google Image Search for CEO Shows Barbie Leading the Way... After a Long Line of Male Execs!",
            "video_word_count": 17,
            "audio_content": "So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So bias is the basis of the data. So what is fairness? Fairness in machine learning refers to the ability of the algorithm to provide you equitable outcomes and",
            "audio_word_count": 149,
            "confidence": 1.0,
            "dominant_emotion": "Happiness",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 113,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 113,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 113,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 113,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 113,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 113,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 113,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 25,
            "start_time": 1370.0,
            "end_time": 1380.0,
            "duration": 10.0,
            "time_formatted": "0:22:50 - 0:23:00",
            "video_content": "Fairness ensures that AI systems treat all individuals and groups with equal consideration free from stereotypes or discriminatory assumptions.",
            "video_word_count": 19,
            "audio_content": "and unbiased representations. For example, if you look at this picture, if you just make it bipartite, this side is for a white-skinned western",
            "audio_word_count": 24,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "no_valid_gaze",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {}
        },
        {
            "slide_id": 26,
            "start_time": 1380.0,
            "end_time": 1400.0,
            "duration": 20.0,
            "time_formatted": "0:23:00 - 0:23:20",
            "video_content": "What is Fairness?\nFairness in Machine Learning refers to the ability of algorithms to provide equitable outcomes and unbiased representations across diverse groups of people, irrespective of their gender, ethnicity, culture, or other characteristics.\nThe image demonstrates how biased training data can lead to AI systems recognizing only the left-hand image as a \"bride,\" while failing to identify the right-hand image equally. This disparity arises from insufficient representation of cultural diversity in the training process, leading to unequal and exclusionary outcomes.\nFairness ensures that AI systems treat all individuals and groups with equal consideration, free from stereotypes or discriminatory assumptions.",
            "video_word_count": 100,
            "audio_content": "western bride and that side is for a typical Indian bride with a darker skin. The machine learning algorithm can tell you that, okay, the left side picture belongs to a bride, but the right side picture doesn't belong to a bride, although both are brides because of the skin tone difference. So these are very famous examples,",
            "audio_word_count": 58,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "center",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 18,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 18,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 18,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 18,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 18,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 17,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 18,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 27,
            "start_time": 1400.0,
            "end_time": 1440.0,
            "duration": 40.0,
            "time_formatted": "0:23:20 - 0:24:00",
            "video_content": "LOW RISK 3\nHIGH RISK 8\nDylan Fugett\nLOW RISK 3\nBernard Parker\nHIGH RISK 10",
            "video_word_count": 16,
            "audio_content": "examples, the Compass Software Results, which actually, which was used for law enforcement in some provinces of USA. And it associated much greater risk with the dark-skinned people because of their skin tone, although their past criminal records were much less severe than the corresponding white-skinned criminals. Similarly, a study by Timnit Gebru, Debora Raji and Joy, their group showed how the Amazon software for face recognition is extremely biased and gets to much more error in recognizing female",
            "audio_word_count": 79,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "center",
            "gaze_recommendation": "Excellent! Maintaining good eye contact with the audience/camera.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 79,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 79,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 79,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 79,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 84,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 79,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 84,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 28,
            "start_time": 1440.0,
            "end_time": 1450.0,
            "duration": 10.0,
            "time_formatted": "0:24:00 - 0:24:10",
            "video_content": "The text on the slide is not clearly visible and appears to be blurred or obscured.",
            "video_word_count": 16,
            "audio_content": "female faces than male faces, in recognizing dark-skinned faces than white-skinned faces and so on. So lack of data diversity and represent gaps,",
            "audio_word_count": 23,
            "confidence": 1.0,
            "dominant_emotion": "Happiness",
            "dominant_gaze": "center",
            "gaze_recommendation": "Excellent! Maintaining good eye contact with the audience/camera.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 11,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 29,
            "start_time": 1450.0,
            "end_time": 1540.0,
            "duration": 90.0,
            "time_formatted": "0:24:10 - 0:25:40",
            "video_content": "Lack of Data Diversity and Representation Gaps\nImage Power and Global Imbalance\nImageNet Statistics: Over 14 million labeled images, heavily sourced from the United States (45.4%), Great Britain (7.6%), Italy (12.3%), Canada (3%), Other Nations (37.8%)\nBias Reflected in Data Sources\nWikipedia Example: Gender Disparity: Fewer than 18% of biographical entries are about women\nVisibility Bias: Articles about women link more to men, making men more visible in search engines\nWomen's Biographies Include More Mentions of Romantic and Family Relationships\nCall to Action for Fairness\nAddressing Social Imbalances: Recognize and mitigate biases in data\nBroaden Dataset Diversity to represent underrepresented groups better\nEnsuring Representation: Capture complexities of gender, ethnicity, and social identities",
            "video_word_count": 112,
            "audio_content": "gaps, the entire machine learning paradigm, the deep learning systems that are nowadays within industry applications, including ResNet, LLNs and so on, they are trained on, most of them are trained on the ImageNet dataset, which contains 14 million-level images. Out of the 14 million-level images, you can see how disparate is the proportion of images from other countries, only 37.8 United States of America, 45.4 and Canada, Italy, all these are white-skinned images from developed countries. But how many people from other population, of the other distribution of the population in the world, can contribute to ImageNet? As a result, because of this disparate distribution, the machine learning system trained on ImageNet also gives you similar outcomes. They are biased, which must be corrected. How can we quantize fairness in AI? There are a lot of indices. I will introduce some of them here before I wrap up. For example, the demographic parity or statistical parity, which says if you have two sensitive groups, then the proportion of their assigning to a particular category should be same in both the groups. And the difference of these two probabilities gives you the DPD, or demographic parity difference. Suppose these are loan applicants and we have both gender, male and female.",
            "audio_word_count": 210,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 323,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 323,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 323,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 289,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 285,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 289,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 285,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 30,
            "start_time": 1540.0,
            "end_time": 1560.0,
            "duration": 20.0,
            "time_formatted": "0:25:40 - 0:26:00",
            "video_content": "Demographic Parity (Statistical Parity): \\(P(\\hat{Y}=1 \\mid A=a)=P(\\hat{Y}=1 \\mid B=b)\\) for or all \\(a, b \\in\\) Sensitive Groups\nDemographic Parity Difference (DPD): DPD = \\(P(\\hat{Y}=1 \\mid A=a)-P(\\hat{Y}=1 \\mid A=b)\\)\nMale Applicants:\n\u2022 Total male applicants = 4\n\u2022 Loan approvals for males: \\(1+0+1+1=3\\) approvals\n\u2022 Proportion of loan approvals for males: \\(3 / 4=0.75\\)",
            "video_word_count": 53,
            "audio_content": "If you look at the male applicants for whom the loan has been approved, it's 3 fourth of their total, 3 fourth fraction of their total population, which is 0.75. For the female applicants, the proportion of loan approval is only two out of four. There are total eight of them. And you",
            "audio_word_count": 53,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "no_valid_gaze",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 21,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 31,
            "start_time": 1560.0,
            "end_time": 1570.0,
            "duration": 10.0,
            "time_formatted": "0:26:00 - 0:26:10",
            "video_content": "Demographic Parity (Statistical Parity): P(\u00a5 = 1|A = a) = P(\u00a5 = 1|A = b) for or all a, b \u2208 Sensitive Groups Demographic Parity Difference (DPD): DPD = P(\u00a5 = 1|A = a) - P(\u00a5 = 1|A = b)",
            "video_word_count": 40,
            "audio_content": "you can see it's only 0.5. So we say the demographic parity is not satisfied if the proportion of loan approval is not equal for males and",
            "audio_word_count": 27,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "no_valid_gaze",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 11,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 32,
            "start_time": 1570.0,
            "end_time": 1620.0,
            "duration": 50.0,
            "time_formatted": "0:26:10 - 0:27:00",
            "video_content": "Demographic Parity (Statistical Parity): \\(P(Y=1|A=a)=P(Y=1|B=b)\\) for all \\(a, b \\in\\) Sensitive Groups\nDemographic Parity Difference (DPD): \\(D P D=\\left|P(Y=1|A=a)-P(Y=1|A=b)\\right|\\)\nMale Applicants:\n- Total male applicants = 4\n- Loan approvals for males: \\(1+0+1+1=3\\) approvals\n- Proportion of loan approvals for males: \\(3 / 4 = 0.75\\)\nFemale Applicants:\n- Total female applicants = 4\n- Loan approvals for females: \\(1+1+0+0=2\\) approvals\n- Proportion of loan approvals for females: \\(2 / 4 = 0.5\\)\nIn this case, the loan approval system is unfair because the approval rate is higher for males (75%) than for females (50%). This indicates a potential bias in the system, and the model does not meet the fairness criterion of Demographic Parity. The unequal approval rates across gender groups could suggest that the system is unfairly favoring one group over the other.",
            "video_word_count": 135,
            "audio_content": "and females. So it's not satisfied. And it says that the loan approval system is unfair because the approval rate is higher for males than for females. This indicates a potential bias in the system. And the model doesn't meet the fairness requirements. So whenever you are marketing industrial software based on AI, the auditing team will look for whether the fairness obeys these quantitative metrics. Similarly, we have equal opportunity in medical AI, which ensures true positive rate across groups. Similar true positive rates, equality of true positive rates across group. And so for example, equal likelihood of correct diagnosis of different ethnic groups, calibration which ensures",
            "audio_word_count": 108,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 73,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 73,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 73,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 72,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 84,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 75,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 75,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 33,
            "start_time": 1620.0,
            "end_time": 1630.0,
            "duration": 10.0,
            "time_formatted": "0:27:00 - 0:27:10",
            "video_content": "\u2022\tOutcome\n\u2022\tAssessment\n\u2022\tFormalities\n\u2022\tMedical\n\u2022\tIM",
            "video_word_count": 10,
            "audio_content": "ensures predicted probabilities match actual outcomes across the group, conditional use accuracy equality, treatment equality and of course favorable treatment",
            "audio_word_count": 20,
            "confidence": 1.0,
            "dominant_emotion": "Sadness",
            "dominant_gaze": "no_valid_gaze",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 7,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 7,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 7,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 7,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 8,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 8,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 8,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 34,
            "start_time": 1630.0,
            "end_time": 1660.0,
            "duration": 30.0,
            "time_formatted": "0:27:10 - 0:27:40",
            "video_content": "Header: Upper Respiratory Tract Infections for Medical Use\nTable: Upper Respiratory Tract Infections for Medical Use\n| Name | Description | Examples |\n|------|-------------|---------|\n| Acute Sinusitis | Inflammation of the sinuses | Sinusitis, sinusitis, sinusitis, sinusitis |\n| Chronic Sinusitis | Inflammation of the sinuses | Sinusitis, sinusitis, sinusitis, sinusitis |\n| Acute Bronchitis | Inflammation of the bronchi | Bronchitis, bronchitis, bronchitis, bronchitis |\n| Chronic Bronchitis | Inflammation of the bronchi | Bronchitis, bronchitis, bronchitis, bronchitis |\n| Acute Pneumonia | Inflammation of the lungs | Pneumonia, pneumonia, pneumonia, pneumonia |\n| Chronic Pneumonia | Inflammation of the lungs | Pneumonia, pneumonia, pneumonia, pneumonia |\n| Acute Laryngitis | Inflammation of the larynx | Laryngitis, laryngitis, laryngitis, laryngitis |\n| Chronic Laryngitis | Inflammation of the larynx | Laryngitis, laryngitis, laryngitis, laryngitis |\n| Acute Pharyngitis | Inflammation of the pharynx | Pharyngitis, pharyngitis, pharyngitis, pharyngitis |\n| Chronic Pharyngitis | Inflammation of the pharynx | Pharyngitis, pharyngitis, pharyngitis, pharyngitis |\n| Acute Otitis Media | Inflammation of the middle ear | Otitis media, otitis media, otitis media, otitis media |\n| Chronic Otitis Media | Inflammation of the middle ear | Otitis media, otitis media, otitis media, otitis media |\n| Acute Urticaria | Hives | Urticaria, urticaria, urticaria, urticaria |\n| Chronic Urticaria | Hives | Urticaria, urticaria, urticaria, urticaria |\n| Acute Hemorrhagic Fever | Severe fever and bleeding | Hemorrhagic fever, hemorrhagic fever, hemorrhagic fever, hemorrhagic fever |\n| Chronic Hemorrhagic Fever | Severe fever and bleeding | Hemorrhagic fever, hemorrhagic fever, hemorrhagic fever, hemorrhagic fever |\n| Acute Myocardial Infarction | Heart attack | Myocardial infarction, myocardial infarction, myocardial infarction, myocardial infarction |\n| Chronic Myocardial Infarction | Heart attack | Myocardial infarction, myocardial infarction, myocardial infarction, myocardial infarction |\n| Acute Myalgia | Muscle pain | Myalgia, myalgia, myalgia, myalgia |\n| Chronic Myalgia | Muscle pain | Myalgia, myalgia, myalgia, myalgia |\n| Acute Pericarditis | Pericarditis | Pericarditis, pericarditis, pericarditis, pericarditis |\n| Chronic Pericarditis | Pericarditis | Pericarditis, pericarditis, pericarditis, pericarditis |\n| Acute Pneumothorax | Pneumothorax | Pneumothorax, pneumothorax, pneumothorax, pneumothorax |\n| Chronic Pneumothorax | Pneumothorax | Pneumothorax, pneumothorax, pneumothorax, pneumothorax |\n| Acute Pulmonary Edema | Pulmonary edema | Pulmonary edema, pulmonary edema, pulmonary edema, pulmonary edema |\n| Chronic Pulmonary Edema | Pulmonary edema | Pulmonary edema, pulmonary edema, pulmonary edema, pulmonary edema |\n| Acute Hemoptysis | Hemoptysis | Hemoptysis, hemoptysis, hemoptysis, hemoptysis |\n| Chronic Hemoptysis | Hemoptysis | Hemoptysis, hemoptysis, hemoptysis, hemoptysis |\n| Acute Cholecystitis | Cholecystitis | Cholecystitis, cholecystitis, cholecystitis, cholecystitis |\n| Chronic Cholecystitis | Cholecystitis | Cholecystitis, cholecystitis, cholecystitis, cholecystitis |\n| Acute Appendicitis | Appendicitis | Appendicitis, appendicitis, appendicitis, appendicitis |\n| Chronic Appendicitis | Appendicitis | Appendicitis, appendicitis, appendicitis, appendicitis |\n| Acute Gastritis | Gastritis | Gastritis, gastritis, gastritis, gastritis |\n| Chronic Gastritis | Gastritis | Gastritis, gastritis, gastritis, gastritis |\n| Acute Hepatitis | Hepatitis | Hepatitis, hepatitis, hepatitis, hepatitis |\n| Chronic Hepatitis | Hepatitis | Hepatitis, hepatitis, hepatitis, hepatitis |\n| Acute Myocardial Infarction | Heart attack | Myocardial infarction, myocardial infarction, myocardial infarction, myocardial infarction |\n| Chronic Myocardial Infarction | Heart attack | Myocardial infarction, myocardial infarction, myocardial infarction, myocardial infarction |\n| Acute Myalgia | Muscle pain | Myalgia, myalgia, myalgia, myalgia |\n| Chronic Myalgia | Muscle pain | Myalgia, myalgia, myalgia, myalgia |\n| Acute Pericarditis | Pericarditis | Pericarditis, pericarditis, pericarditis, pericarditis |\n| Chronic Pericarditis | Pericarditis | Pericarditis, pericarditis, pericarditis, pericarditis |\n| Acute Pneumothorax | Pneumothorax | Pneumothorax, pneumothorax, pneumothorax, pneumothorax |\n| Chronic Pneumothorax | Pneumothorax | Pneumothorax, pneumothorax, pneumothorax, pneumothorax |\n| Acute Pulmonary Edema | Pulmonary edema | Pulmonary edema, pulmonary edema, pulmonary edema, pulmonary edema |\n| Chronic Pulmonary Edema | Pulmonary edema | Pulmonary edema, pulmonary edema, pulmonary edema, pulmonary edema |\n| Acute Hemoptysis | Hemoptysis | Hemoptysis, hemoptysis, hemoptysis, hemoptysis |\n| Chronic Hemoptysis | Hemoptysis | Hemoptysis, hemoptysis, hemoptysis, hemoptysis |\n| Acute Cholecystitis | Cholecystitis | Cholecystitis, cholecystitis, cholecystitis, cholecystitis |\n| Chronic Cholecystitis | Cholecystitis | Cholecystitis, cholecystitis, cholecystitis, cholecystitis |\n| Acute Appendicitis | Appendicitis | Appendicitis, appendicitis, appendicitis, appendicitis |\n| Chronic Appendicitis | Appendicitis | Appendicitis, appendicitis, appendicitis, appendicitis |\n| Acute Gastritis | Gastritis | Gastritis, gastritis, gastritis, gastritis |\n| Chronic Gastritis | Gastritis | Gastritis, gastritis, gastritis, gastritis |\n| Acute Hepatitis | Hepatitis | Hepatitis, hepatitis, hepatitis, hepatitis |\n| Chronic Hepatitis | Hepatitis | Hepatitis, hepatitis, hepatitis, hepatitis |",
            "video_word_count": 756,
            "audio_content": "treatment equality which are all trying to see how equal treatment facilities have been provided across different demographics or different classes that are inside your training data or inside your use case. And in medical AI, we can always fit a fairness aware loss function. For example, when you train the particular medical deep learning system, your original cost function could be the L task and which is regularized",
            "audio_word_count": 69,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 63,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 63,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 63,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 63,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 64,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 63,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 64,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 35,
            "start_time": 1660.0,
            "end_time": 1700.0,
            "duration": 40.0,
            "time_formatted": "0:27:40 - 0:28:20",
            "video_content": "Fairness Approaches in Medical LLMs\nMethods & Techniques\n1. Data Augmentation with Balanced Representation\n2. Fairness-aware Loss Function\n3. Debiasing through Model Architecture\nFairness Evaluation\n1. WEAT (Word Embedding Association Test)\n2. Demographic Parity Difference\n3. Equal Opportunity Difference...and so on\nImplementation Focus:\n\u2022 Demographic Parity in Diagnoses\n\u2022 Equal Opportunity in Treatment\n\u2022 Balanced Performance Across Groups\nExample: Equal Opportunity Loss\nFor equal opportunity, the fairness term can penalize differences in True Positive Rates (TPR) between sensitive groups (e.g., Male A = 0, Female A = 1):\nL_Fair = L_Task + \u03bb * (TPR_A=0 - TPR_A=1)2",
            "video_word_count": 97,
            "audio_content": "regularized by the difference between the true positive rate between two communities for one A equal to zero, maybe the dark skin people and the other A equal to one, maybe for the light skin people. You try to also minimize the square of this difference or maybe for male and female, you try to minimize the square of this difference. So defining fairness and bias in healthcare data, we can quantify them using several factors including inclusivity, diversity and levels. Metrics may include representation across gender, skin tone, ethnic group and age. So a person from India, given the same",
            "audio_word_count": 101,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 74,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 77,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 74,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 77,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 36,
            "start_time": 1700.0,
            "end_time": 1720.0,
            "duration": 20.0,
            "time_formatted": "0:28:20 - 0:28:40",
            "video_content": "Defining Fairness in Biometric and Healthcare Data\nFairness Factors for Dataset Evaluation\nWe quantify dataset fairness using three key factors:\n1. Inclusivity\n\u25cb Are different groups of people represented in the dataset?\n\u25cb Metrics include representation across gender, skin tone, ethnic group, and age.\n2. Diversity\n\u25cb Is the dataset balanced for all groups?\n\u25cb Ensures equitable representation and evaluation across skills, Age, and Ethnicity.\n3. Labels\n\u25cb How accurate and reliable is the dataset i.e. how reliable is the learning and evaluation?",
            "video_word_count": 83,
            "audio_content": "same age and maybe much healthier or obese and a person from India, same age, not that obese, you cannot prescribe similar medicines for treating their diabetes. Okay? Similarly, the most important part comes when it is about skin lesion detection.",
            "audio_word_count": 41,
            "confidence": 1.0,
            "dominant_emotion": "Neutral",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 21,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 21,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 37,
            "start_time": 1720.0,
            "end_time": 1760.0,
            "duration": 40.0,
            "time_formatted": "0:28:40 - 0:29:20",
            "video_content": "One of the Major Challenges in Medical AI: Attribute Generalization & Class Imbalance\nProblem: Skin Tone Bias and Class Imbalance in Skin Lesion Classification\nDeep learning models for skin lesion classification often face two significant challenges: bias towards dominant skin tones (mainly pale skin) and class imbalance, as datasets are disproportionately sourced from lighter-skinned individuals. This issue highlights the need for better attribute generalization and more balanced data representation to improve model fairness and performance across diverse skin tones.\nMotivation:\n\u2022 Machine learning algorithms need to perform robustly across demographics for equitable and generalizable results.\n\u2022 Skin cancer can occur in darker skin tones as well, necessitating fair representation in datasets and models.\n\u2022 Persistent problems within machine learning fairness and health equity.",
            "video_word_count": 123,
            "audio_content": "So one last use case for us, this is one problem that we are trying to solve. Skin tone bias and class imbalance for skin lesion classification. Deep learning models when they come to melanoma, melanoma is a type of skin cancer which is very common among the dark skin people. But there are data sets for training such, you know, medical deep learning systems which are extremely biased towards the, you know, white skin people and they cannot easily detect the melanoma skin patches or lesions on the dark skin people. If you look at these two are the representative data",
            "audio_word_count": 102,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 74,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 74,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 74,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 63,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 74,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 72,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 74,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 38,
            "start_time": 1760.0,
            "end_time": 1820.0,
            "duration": 60.0,
            "time_formatted": "0:29:20 - 0:30:20",
            "video_content": "Take the ISIC-18 and ASAN datasets, for example\u2014both showcase a critical flaw: there are hardly 4 or 5 images of dark skin tones in ISIC-18 (as reported in the literature), while ASAN lacks sufficient representation of lighter skin tones.\nWhat does this mean?\nA network trained on ISIC-18 may struggle with darker skin tones, while one trained on ASAN could fail with lighter skin tones.\nHow can we trust AI for skin lesion classification if it can't handle the diversity of real-world skin types?",
            "video_word_count": 84,
            "audio_content": "data sets, ICIC 18 and ASAN. Both the data sets, a network trained on ICIC 18 may struggle with darker skin tones while the one trained on ASAN could also fail on light skin tones and for training deep neural networks on, you know, skin segmentation or lesion detection, these two are our only best practices. They are very well documented, they satisfy all the medical parameters. So can we really overcome these challenges with limited data sets? The answer is yes. We have to augment them, we have to mix their patterns, we have to make a smooth transition, only then it is possible. So to meet up these questions, recently this year we published one very nice paper in the Mikae conference in medical imaging and we gave a solution where we are using data augmentation through adaptive mix-up",
            "audio_word_count": 141,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 93,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 93,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 93,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 89,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 89,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 82,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 72,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 39,
            "start_time": 1820.0,
            "end_time": 1880.0,
            "duration": 60.0,
            "time_formatted": "0:30:20 - 0:31:20",
            "video_content": "Our Proposed Solution:\nWe tackle the challenges of class imbalance and skin tone bias (specifically the issue of missing colour tones) in lesion classification with a novel approach. Our framework is outlined in the framework below:\nSampling and Augmentation using Mixup Method\nBased on the features, calculate the probability of corresponding samples to each class\nMake the original distribution of data\nCreate a new sample\nCalculate and test\nTakeaways:\n\u2022 We propose a novel data augmentation technique to address skin tone bias and class imbalance in skin lesion classification using an adaptive mixup sampling strategy for cross-discriminating diverse skin tones.\n\u2022 Our approach is validated on two benchmark datasets: ISIC 2018 (mostly Caucasian) and ASIAN (primarily Asian), highlighting dataset bias and imbalance.\n\u2022 Results show significant improvements, yielding a fairer and more generalizable classifier for diverse patient demographics, with potential application in clinical decision support systems (CDSS).\n\u2022 The issue of missing attributes and class imbalance remains, presenting opportunities for further refinement.\n\u2022 Future work could involve expanding the meta-set to include more skin tones, dynamic sampling strategies, and testing on additional datasets for broader applicability.",
            "video_word_count": 186,
            "audio_content": "mix-up sampling and also cross-sampling across diverse skin tones. Basically we are mixing the lighter and darker skin tones to make a smooth transition and creating new images to make our classifier much less biased towards the, you know, the darker skin patches. This work and all its codes, etc., are available from our, the website of Mikae and it may mark a significant step because we can actually artificially populate the data sets. So, for emerging issues that the modern AI powered by LLMs and VLMs must overcome bias, lack of explainability, ethnical concerns and misinformation. We have miles to go before we can do that. So, we have a lot of information about AI systems. Explainability is very important. It is an essential condition for marketing any such AI system.",
            "audio_word_count": 132,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 126,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 126,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 126,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 126,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 126,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 123,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 123,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 40,
            "start_time": 1880.0,
            "end_time": 1890.0,
            "duration": 10.0,
            "time_formatted": "0:31:20 - 0:31:30",
            "video_content": "Emerging Issues AI Will OvercomeExplorability is EssentialTransparency Diversification Bias MitigationContinuous Quality Monitoring",
            "video_word_count": 12,
            "audio_content": "Bias and fairness, we have to be very careful about them. Continuous monitoring is essential because the demography and the distribution",
            "audio_word_count": 21,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "right",
            "gaze_recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 11,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 11,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 9,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 10,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 41,
            "start_time": 1890.0,
            "end_time": 1920.0,
            "duration": 30.0,
            "time_formatted": "0:31:30 - 0:32:00",
            "video_content": "Miles to go before you sleep...\n\u2022 Explainability is Essential: AI in healthcare must be interpretable to build trust and ensure clinicians understand decision-making.\n\u2022 Bias and Fairness: Addressing bias in LLMs is crucial to avoid disparities in healthcare outcomes across different demographic groups.\n\u2022 Transparency Builds Trust: Transparent models are key to gaining acceptance from clinicians, patients, and regulatory bodies.\n\u2022 Bias Mitigation: Techniques like data augmentation and fairness constraints should be used to reduce biases in healthcare AI.\n\u2022 Diverse Validation: Models should be tested on diverse datasets to ensure they work equitably for all populations.\n\u2022 Continuous Monitoring: Ongoing AI performance and fairness tracking is necessary to ensure long-term effectiveness.\n\u2022 Patient-Centric Design: AI should support clinicians in decision-making without replacing human judgment.\n\u2022 Adoption through Explainability: Clear, understandable explanations of AI decisions increase adoption by healthcare professionals.",
            "video_word_count": 141,
            "audio_content": "of the training data can change. Nowadays all AI systems operate through lifelong learning. And for those new things also, the bias and fairness must be mitigated. And finally, adoption through, you know, explainability, clear, understandable explanations of AI decisions increase the adoption for healthcare professionals, in fact for all professionals who are using AI. So, with this, I would like to thank you very much for your kind attention. This is a picture of Professor Prashant Chandramahalanobish",
            "audio_word_count": 78,
            "confidence": 1.0,
            "dominant_emotion": "Anger",
            "dominant_gaze": "center",
            "gaze_recommendation": "Excellent! Maintaining good eye contact with the audience/camera.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 64,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 64,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 64,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 45,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 52,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 43,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 46,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        },
        {
            "slide_id": 42,
            "start_time": 1920.0,
            "end_time": 1966.24,
            "duration": 46.24000000000001,
            "time_formatted": "0:32:00 - 0:32:46",
            "video_content": "Thanks a lot for your kind attention...\n\u0421\u043f\u0430\u0441\u0438\u0431\u043e \u0437\u0430 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435...",
            "video_word_count": 10,
            "audio_content": "Chandramahalanobish who was the founding father of my institute, Indian Statistical Institute, who is welcoming Professor A.M. Kolomogorov and other giant statistician from Soviet Russia long back in April 1962. So, thank you very much for your kind attention. Professor Vagatam Das please applause to the speakers. Thank you. Thank you very much. You are welcome here in Russia. Thank you. Thank you very much. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you.",
            "audio_word_count": 79,
            "confidence": 1.0,
            "dominant_emotion": "Sadness",
            "dominant_gaze": "right",
            "gaze_recommendation": "Try to maintain more consistent eye contact with your audience.",
            "gesture_joint_details": {
                "head": {
                    "valid_frames": 81,
                    "recommendation": "Reduce excessive head movement for a calmer presence."
                },
                "left_shoulder": {
                    "valid_frames": 81,
                    "recommendation": "Reduce excessive left shoulder movement for a calmer presence."
                },
                "right_shoulder": {
                    "valid_frames": 81,
                    "recommendation": "Reduce excessive right shoulder movement for a calmer presence."
                },
                "left_elbow": {
                    "valid_frames": 79,
                    "recommendation": "Reduce excessive left elbow movement for a calmer presence."
                },
                "right_elbow": {
                    "valid_frames": 90,
                    "recommendation": "right elbow movement is balanced."
                },
                "left_wrist": {
                    "valid_frames": 85,
                    "recommendation": "Reduce excessive left wrist movement for a calmer presence."
                },
                "right_wrist": {
                    "valid_frames": 88,
                    "recommendation": "Reduce excessive right wrist movement for a calmer presence."
                }
            }
        }
    ],
    "speech_analysis": {
        "full_transcription": "once again welcome welcome back everyone here in the audience everyone watching the webcast this is day three the last day of ai journey conference and today we talk all things science and research im happy to welcome on the stage one of the most frequently cited researchers the author of almost research articles the founder and editor of international scientific publications please welcome professor swagatam das professor of the indian statistics university swagatam das scientific approach the building of an interpretable fair and transparent ai for the future and i represent the indian statistical institute an institute which pioneered the study of artificial intelligence more than six decades back besides pioneering the study of statistics in entire asia and in next minutes or so im going to share with you some of my fascinating experiences on working on and with the new generation artificial intelligence systems based on foundation models vision language models and their fairness and bias aspects in context to medical ai and if you take a look at this beginning slide back in years back from now artificial intelligence started to pour into machine learning and it was basically one particular machine learning model trained for one particular task and then it forgets everything you start training another model from scratch for another task and this went on for every different data set for every medical situation or every situation in banking and finance fraud detection you will train a model from scratch and then the model forgets everything once the task is over therefrom we gradually graced into transfer learning where the model doesnt really forget it gets trained on a particular type of data and it remembers the knowledge of that training and later on it can adapt and extrapolate that knowledge to a new situation so machine learning model which learns to differentiate between small scars and big tracks can also differentiate between big cargo vans and big aeroplanes they can understand these are big vehicles somehow by extrapolating their knowledge therein came the transfer learning which became very popular since s or so and now we have transgraced towards foundation models these are extremely big huge parametric machine learning models usually neural networks that are trained on massive amount of external data and they can perform versatile functionalities so if you have been using any large language model like chat gpt or some specific model for russia you should know that these models are basically built on foundation models trained on massive amount of external data internetbased techs repositories and then with simple human prompting prompting means programming in your own speakable language so you give the machine some instruction in your own speakable language and the machine can perform all those finetuned jobs with little or even no examples in which case we call it zeroshot situation so we are transgracing from taskspecific machine learning models towards foundation models in last maybe i say five six years or so and for example this is the most popular foundation model in computational vision computer vision application just published in we call it sam segment anything model and here what you see is you input a picture and you can segment out any object from the picture you can ask visual questions on that object for example you can segment the cat with black ears by simply with text prompt that just mark me the cat with black ears or just by specifying an approximate parametric bounding box around it now we are in the era of vision language models and the interface with users is chat gpt version four gpt four is a commercial vision language model which can actually align and fuse both visual and textual representation so llm doesnt apply to languages only anymore they are now meant to process images and give answers towards that to from those images make changes in those images as per user specification so you see in this particular situation when you upload an image and ask is one cat behind the other the machine answers yes one cat is really behind the other and then you can segment out that cat by specifying segment the striped cat zero shot means you give no example you specify nothing about the striped cat one shot means you give at least one example and the vision language model which by jargon a foundation model can do all these versatile tasks with little or no explicit instruction from the user so since i mean i know russia is the land of great mathematicians so just this ai foundation model was published very recently in the nature journal we call it the alpha geometry model and it scored on average which is very close to the score of a gold medalist for international math olympiad problem it can solve geometry problems by using abstract constructions as you can see it is proving some sort of congruency or equality of angles given the equality of sides for an isocellous triangle so nicely now with great responsible great power comes also huge and great responsibility need of the hour when we are trying to adopt such vision language models or foundation models for several tasks around us in healthcare sector in financial sector in weather analytics in astronomy we are not in computational physics chemistry the need of the hour is of course responsible ai which has three most important facets the first one is fairness so fairness means the ai algorithms and their outcomes must not favor some specific group or community unduly and it should give us equitable outcomes across all possible demographies genders religions race etc which may be reflected in its training data then we have interpretability interpretability means every user of the ai system should understand about the internal structure and workflow of the model if it is a huge deep neural network which comes to us like a black box then this is a limitation on the interpretability of such networks so how the model processes any input to its output what is the workflow if that is understandable we call it an interpretable ai model and the final one is of course explainability the most important facet when you are using an ai system for your own business or company or academic purpose for a particular input why the ai system is infaring something giving you some decision that must be understood the ai system must be able to express that so here there is a black box model which tries to find out some sort of anomaly in the long xray image and it says the patient has a likelihood of developing pneumonia but if it is an explainable ai system it should point out the exact portion of the long xray image the fibrosis or the white cloudish pattern to say why it thinks the patient will have pneumonia so these three facets if theyre available in your ai system if theyre understood very much evident during the audit of your algorithm then everyone will accept it and they will say you are doing responsible artificial intelligence however there is always a tradeoff in the world of science a tradeoff classically could be between speed versus accuracy or bandwidth versus time and so on here also the fundamental tradeoff is the more complicated your model becomes its prediction accuracy enhances and its explainability goes down down down thats why deep neural networks they became hugely popular since but the greatest criticism for them especially in the academic community was their black box no one understands how they function on the other hand decision trees which are basically a computer data structure representation of a set of efails rules are very much explainable if the features obey certain rules then the outcome is this or that its extremely transparent its applicability in the real world is very low because its accuracy is no it doesnt come into any comparison for deep neural networks so there are certain ways of navigating this problem one is can we have a deep neural network fit it to map an input into an output and then just like the concept of an equivalent resistance can we use a decision tree also to map the same inputs to the same outputs then by looking at this explainable decision tree we know how the deep neural network emphasizes certain features or characteristics of the input objects and infarts something this is one way of making a black box model explainable then interpretable models like support vector machines ao ghbns and of course random forests and so on where accuracy is also not that high but they have been playing a very good role in causal inference and finally model induction means we can always train a model between the same inputoutput mapping scenarios to explain a black box model if we add these three techniques then the explainability of all these models can improve now coming to my use case the medical ai artificial intelligence is being used for diagnosis and medical report generation and explaining the outcomes of an automatic diagnostic system back to the clinicians staging of different types of tumors and cancers for a long time explainability plays a very important role in medical ai it can bridge the gap between the medical experts or clinicians and the outcomes from an ai system and on the other hand fairness is a mandatory feature for any medical ai system it should not give disparate outcomes based on gender or demography or scheme color etc etc etc so thats why all medical ai systems in india and im sure in other countries go through algorithmic audit where they check the training data they check the outcome and they check how much imbalance is there how much disparity is there in prescribing certain things for certain genders or race etc so the traditional approaches to explainability during the prella meta was like this this is a very common thing we call it lime or local interpretable model agnostic explanations you give an image to any machine learning system and the machine learning system says its a frog with probability now you segment out certain small portions of the image and you plug in those parts into the same deep learning system and see how many times with which probability its being predicted as frog if you look at these three segments you will see that the top one which segments out the mouth and eyes part of the frog for that portion highest probability in the frog class is coming so we can fit these different predictions from the system through a locally weighted regression and then the regression pick will tell us okay this picture is classified as frog because of this portion this mouth and the eye part okay that is an explanation explanation means why the machine learning system thinks its a frog and this is a model agnostic that means it doesnt depend whether you are using a support vector machine or you are using a deep neural network or you are using a nice bayesian and so on then there comes convolutional neural networks for image classification and in that case we use during the prella meta prella meta means up to obviously because in november with openais publishing of chat gpt llm became very familiar to the broader world and for prella meta or for specific applications of medical ai gradient weighted cam or class activation maps is very important which actually highlights the regions of the image where because of those four pixels the gradient change is maximum so those pixels are most emphasized during the training process of the neural network so if you look at this picture and if the neural network has to find out the cat it will actually do so in the second picture the cat is found out based on those portions that are highlighted and the dog is found out in the third picture based on those portions highlighted this is one of our work just in this year in specific medical diagnostics of alzheimers patients and we used three different modalities the mri images the genetic data and the electronic health records and now we are showing once the three classes cognitively normal mild cognitive impairment and alzheimers disease these are the three classes that to which every patient should be mapped once we get those classes the right side heat maps are basically showing which portion of the brain of the mri scan is prompting the neural network to put the image into one of these classes sorry so with llm coming into picture traditional methods got lot of transformed okay now we have the capability of multimodal explanations dynamic fairness assessment and generation of medical reports which could bridge the outcome of the automatic diagnostic system towards patients and also which could bridge the outcome with the clinicians through explainable interface fairness also evolved llms could be used for continuous monitoring and contextual fairness evaluation across multiple demographic intersections and you know inside your data if the domain changes if there is a shift in the probability distribution of the data that could also be captured through the fairness evolution and recent llvlms vision language models in the medical domain include for example medpump which is not publicly released not open source from google you upload any such picture of a chest xray image or something and it finds out it writes down the findings of like a pathological lab expert on the other hand medflamingo which is more open source you upload the picture of your lungs xray image and it can tell you what is wrong with the lungs it will say okay blunt trauma to the left lung with hemothorax some sort of blood is being accumulated over there so these are some most recent vlms in the domain of medical ai and what we are trying to do is with llm is that we are trying to make the medical reports simplified more understandable by common people like us i dont know about russia but in india also the doctors sometimes write down the reports in a very cryptic medical jargon language which people from my family may not be able to understand clearly so what we are doing is through a chain prompting technique we are using the llma model for updating the medical reports so if you look at the right hand texts in red and in green youll see that okay the original medical report says both lungs are clear and expanded heart and medial stimuli normal so and the simplified version says both of your lungs look clear and are expanded to their full size your heart and space around it appear normal and if you look on the top one it is more involved no focal air space disease pleural effusion or pneumothorax cardiomedicine silhouette is within normal limits so these are medical jargons not understandable by common man and when our system simplifies it it reads something like there are no areas of solid lung tissue no fluid in the lungs no collapsed lung the size and shape of the heart and the surrounding area appear normal there is no free air beneath the diaphragm which is more i mean a clear error and ready to interpret by a common human being so bias and fairness in modern ai i will talk about little bit of this before i can wrap up so bias always refers to systematic error in the performance of the model because of giving undue weightage to particular it could be particular gender race religion some particular group okay so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so bias is the basis of the data so what is fairness fairness in machine learning refers to the ability of the algorithm to provide you equitable outcomes and unbiased representations for example if you look at this picture if you just make it bipartite this side is for a whiteskinned western bride and that side is for a typical indian bride with a darker skin the machine learning algorithm can tell you that okay the left side picture belongs to a bride but the right side picture doesnt belong to a bride although both are brides because of the skin tone difference so these are very famous examples the compass software results which actually which was used for law enforcement in some provinces of usa and it associated much greater risk with the darkskinned people because of their skin tone although their past criminal records were much less severe than the corresponding whiteskinned criminals similarly a study by timnit gebru debora raji and joy their group showed how the amazon software for face recognition is extremely biased and gets to much more error in recognizing female faces than male faces in recognizing darkskinned faces than whiteskinned faces and so on so lack of data diversity and represent gaps the entire machine learning paradigm the deep learning systems that are nowadays within industry applications including resnet llns and so on they are trained on most of them are trained on the imagenet dataset which contains millionlevel images out of the millionlevel images you can see how disparate is the proportion of images from other countries only united states of america and canada italy all these are whiteskinned images from developed countries but how many people from other population of the other distribution of the population in the world can contribute to imagenet as a result because of this disparate distribution the machine learning system trained on imagenet also gives you similar outcomes they are biased which must be corrected how can we quantize fairness in ai there are a lot of indices i will introduce some of them here before i wrap up for example the demographic parity or statistical parity which says if you have two sensitive groups then the proportion of their assigning to a particular category should be same in both the groups and the difference of these two probabilities gives you the dpd or demographic parity difference suppose these are loan applicants and we have both gender male and female if you look at the male applicants for whom the loan has been approved its fourth of their total fourth fraction of their total population which is for the female applicants the proportion of loan approval is only two out of four there are total eight of them and you can see its only so we say the demographic parity is not satisfied if the proportion of loan approval is not equal for males and females so its not satisfied and it says that the loan approval system is unfair because the approval rate is higher for males than for females this indicates a potential bias in the system and the model doesnt meet the fairness requirements so whenever you are marketing industrial software based on ai the auditing team will look for whether the fairness obeys these quantitative metrics similarly we have equal opportunity in medical ai which ensures true positive rate across groups similar true positive rates equality of true positive rates across group and so for example equal likelihood of correct diagnosis of different ethnic groups calibration which ensures predicted probabilities match actual outcomes across the group conditional use accuracy equality treatment equality and of course favorable treatment equality which are all trying to see how equal treatment facilities have been provided across different demographics or different classes that are inside your training data or inside your use case and in medical ai we can always fit a fairness aware loss function for example when you train the particular medical deep learning system your original cost function could be the l task and which is regularized by the difference between the true positive rate between two communities for one a equal to zero maybe the dark skin people and the other a equal to one maybe for the light skin people you try to also minimize the square of this difference or maybe for male and female you try to minimize the square of this difference so defining fairness and bias in healthcare data we can quantify them using several factors including inclusivity diversity and levels metrics may include representation across gender skin tone ethnic group and age so a person from india given the same age and maybe much healthier or obese and a person from india same age not that obese you cannot prescribe similar medicines for treating their diabetes okay similarly the most important part comes when it is about skin lesion detection so one last use case for us this is one problem that we are trying to solve skin tone bias and class imbalance for skin lesion classification deep learning models when they come to melanoma melanoma is a type of skin cancer which is very common among the dark skin people but there are data sets for training such you know medical deep learning systems which are extremely biased towards the you know white skin people and they cannot easily detect the melanoma skin patches or lesions on the dark skin people if you look at these two are the representative data sets icic and asan both the data sets a network trained on icic may struggle with darker skin tones while the one trained on asan could also fail on light skin tones and for training deep neural networks on you know skin segmentation or lesion detection these two are our only best practices they are very well documented they satisfy all the medical parameters so can we really overcome these challenges with limited data sets the answer is yes we have to augment them we have to mix their patterns we have to make a smooth transition only then it is possible so to meet up these questions recently this year we published one very nice paper in the mikae conference in medical imaging and we gave a solution where we are using data augmentation through adaptive mixup sampling and also crosssampling across diverse skin tones basically we are mixing the lighter and darker skin tones to make a smooth transition and creating new images to make our classifier much less biased towards the you know the darker skin patches this work and all its codes etc are available from our the website of mikae and it may mark a significant step because we can actually artificially populate the data sets so for emerging issues that the modern ai powered by llms and vlms must overcome bias lack of explainability ethnical concerns and misinformation we have miles to go before we can do that so we have a lot of information about ai systems explainability is very important it is an essential condition for marketing any such ai system bias and fairness we have to be very careful about them continuous monitoring is essential because the demography and the distribution of the training data can change nowadays all ai systems operate through lifelong learning and for those new things also the bias and fairness must be mitigated and finally adoption through you know explainability clear understandable explanations of ai decisions increase the adoption for healthcare professionals in fact for all professionals who are using ai so with this i would like to thank you very much for your kind attention this is a picture of professor prashant chandramahalanobish who was the founding father of my institute indian statistical institute who is welcoming professor am kolomogorov and other giant statistician from soviet russia long back in april so thank you very much for your kind attention professor vagatam das please applause to the speakers thank you thank you very much you are welcome here in russia thank you thank you very much thank you thank you thank you thank you thank you thank you thank you",
        "filler_words": {
            "so": 121,
            "basically": 5,
            "really": 3,
            "like": 9,
            "just": 7,
            "actually": 5,
            "okay": 8,
            "right": 3
        },
        "filler_phrases": {
            "you see": 2,
            "i mean": 2,
            "sort of": 3,
            "you know": 6
        },
        "pause_intervals": [
            [
                45.2,
                71.82
            ],
            [
                345.06,
                345.84
            ],
            [
                683.34,
                684.4
            ],
            [
                761.96,
                763.8
            ],
            [
                839.62,
                840.76
            ],
            [
                947.76,
                953.96
            ],
            [
                1057.52,
                1058.6
            ],
            [
                1353.52,
                1354.4
            ],
            [
                1634.26,
                1635.12
            ],
            [
                1675.98,
                1676.78
            ],
            [
                1853.8,
                1882.3
            ],
            [
                1930.12,
                1959.44
            ],
            [
                1959.82,
                1966.16
            ]
        ],
        "background_noise_intervals": [
            [
                17.46,
                17.92
            ]
        ]
    },
    "summary": {
        "total_video_words": 8126,
        "total_audio_words": 4609,
        "average_slide_duration": 46.815238095238094,
        "total_filler_words": 161,
        "total_filler_phrases": 13
    },
    "clothing_analysis": {
        "is_appropriate": false,
        "detected_attributes": [
            "graphic",
            "solid",
            "casual"
        ],
        "recommendation": "Consider avoiding: casual for a formal presentation. Top detected: graphic (0.90), solid (0.08), casual (0.01)."
    },
    "emotion_analysis": {
        "overall_stats": {
            "most_common_emotion": "Anger",
            "confidence": 2.0860555171966553,
            "emotion_distribution": {
                "Neutral": 462,
                "Fear": 101,
                "Happiness": 172,
                "Disgust": 234,
                "Contempt": 9,
                "Anger": 733,
                "Surprise": 286,
                "Sadness": 322
            },
            "total_faces_analyzed": 2319,
            "average_scores": {
                "Anger": 2.0860555171966553,
                "Contempt": -0.5480714440345764,
                "Disgust": 0.42419224977493286,
                "Fear": -0.3553934097290039,
                "Happiness": -0.36234810948371887,
                "Neutral": 1.8423329591751099,
                "Sadness": 1.402032732963562,
                "Surprise": 0.7570533156394958
            }
        },
        "transition_types": {
            "Anger \u2192 Disgust": 2,
            "Disgust \u2192 Anger": 2,
            "Anger \u2192 Neutral": 5,
            "Neutral \u2192 Anger": 5,
            "Anger \u2192 Surprise": 1,
            "Surprise \u2192 Anger": 1,
            "Anger \u2192 Happiness": 1,
            "Happiness \u2192 Neutral": 1,
            "Neutral \u2192 Happiness": 1,
            "Happiness \u2192 Anger": 1,
            "Anger \u2192 Sadness": 2,
            "Sadness \u2192 Anger": 1
        },
        "stability": {
            "overall_score": 0.5049070275864425,
            "category": "Moderately Stable"
        },
        "anomalies": [
            {
                "type": "technical_confidence_drop",
                "location": "Slide 24 \u2192 25",
                "severity": "medium",
                "description": "Technical detection issue: confidence dropped by 183.6%",
                "from_emotion": "Happiness",
                "to_emotion": "Neutral",
                "from_confidence": 4.6838969958795085,
                "to_confidence": 2.847511427743094
            },
            {
                "type": "technical_confidence_drop",
                "location": "Slide 28 \u2192 29",
                "severity": "medium",
                "description": "Technical detection issue: confidence dropped by 264.4%",
                "from_emotion": "Happiness",
                "to_emotion": "Anger",
                "from_confidence": 6.087500810623169,
                "to_confidence": 3.443420113886104
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 1",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.144145581159699
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 3",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.2349441701715644
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 6",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.5604983936121433
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 7",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.514867043930646
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 11",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.22591041937107
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 12",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.7981425672769547
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 17",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.3373232300464926
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 20",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.8939203299632688
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 21",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.876478420363532
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 23",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.348554443894771
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 29",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.443420113886104
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 32",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.1950378700306543
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 34",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.633701038360596
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 35",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.5054862715981225
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 37",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.3220016749008843
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 38",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.182569995869038
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 39",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.182947098084216
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 40",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.2823626518249513
            },
            {
                "type": "severe_negative_emotion",
                "location": "Slide 41",
                "severity": "high",
                "description": "Detected severe Anger emotion with high confidence",
                "emotion": "Anger",
                "confidence": 3.0484271304947987
            },
            {
                "type": "emotional_deterioration",
                "location": "Slide 10 \u2192 11",
                "severity": "high",
                "description": "Emotional deterioration: Neutral \u2192 Anger",
                "intensity_change": 4,
                "from_confidence": 3.5215445010349002,
                "to_confidence": 3.22591041937107
            },
            {
                "type": "emotional_deterioration",
                "location": "Slide 16 \u2192 17",
                "severity": "high",
                "description": "Emotional deterioration: Neutral \u2192 Anger",
                "intensity_change": 4,
                "from_confidence": 3.303114687524191,
                "to_confidence": 3.3373232300464926
            },
            {
                "type": "emotional_deterioration",
                "location": "Slide 18 \u2192 20",
                "severity": "medium",
                "description": "Emotional deterioration: Surprise \u2192 Anger",
                "intensity_change": 2,
                "from_confidence": 2.9513210524683413,
                "to_confidence": 3.8939203299632688
            },
            {
                "type": "emotional_deterioration",
                "location": "Slide 22 \u2192 23",
                "severity": "high",
                "description": "Emotional deterioration: Neutral \u2192 Anger",
                "intensity_change": 4,
                "from_confidence": 2.718306303024292,
                "to_confidence": 3.348554443894771
            },
            {
                "type": "emotional_deterioration",
                "location": "Slide 28 \u2192 29",
                "severity": "high",
                "description": "Emotional deterioration: Happiness \u2192 Anger",
                "intensity_change": 3,
                "from_confidence": 6.087500810623169,
                "to_confidence": 3.443420113886104
            },
            {
                "type": "emotional_deterioration",
                "location": "Slide 31 \u2192 32",
                "severity": "high",
                "description": "Emotional deterioration: Neutral \u2192 Anger",
                "intensity_change": 4,
                "from_confidence": 3.6537914276123047,
                "to_confidence": 3.1950378700306543
            },
            {
                "type": "emotional_deterioration",
                "location": "Slide 36 \u2192 37",
                "severity": "high",
                "description": "Emotional deterioration: Neutral \u2192 Anger",
                "intensity_change": 4,
                "from_confidence": 3.738800287246704,
                "to_confidence": 3.3220016749008843
            }
        ],
        "improvements": [
            {
                "from_slide": 7,
                "to_slide": 8,
                "from_emotion": "Anger",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 8,
                "to_slide": 10,
                "from_emotion": "Neutral",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 12,
                "to_slide": 13,
                "from_emotion": "Anger",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 13,
                "to_slide": 14,
                "from_emotion": "Neutral",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 14,
                "to_slide": 15,
                "from_emotion": "Neutral",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 15,
                "to_slide": 16,
                "from_emotion": "Neutral",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 17,
                "to_slide": 18,
                "from_emotion": "Anger",
                "to_emotion": "Surprise",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 21,
                "to_slide": 22,
                "from_emotion": "Anger",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 23,
                "to_slide": 24,
                "from_emotion": "Anger",
                "to_emotion": "Happiness",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 25,
                "to_slide": 26,
                "from_emotion": "Neutral",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 26,
                "to_slide": 27,
                "from_emotion": "Neutral",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 29,
                "to_slide": 30,
                "from_emotion": "Anger",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 30,
                "to_slide": 31,
                "from_emotion": "Neutral",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            },
            {
                "from_slide": 35,
                "to_slide": 36,
                "from_emotion": "Anger",
                "to_emotion": "Neutral",
                "type": "emotional_improvement"
            }
        ]
    },
    "gaze_analysis": {
        "overall_summary": {
            "gaze_distribution": {
                "no_face": 33.5,
                "right": 26.4,
                "center": 40.0,
                "left": 0.0
            },
            "most_common_gaze": "center",
            "valid_gaze_ratio": 0.66,
            "recommendation": "Try to maintain more consistent eye contact with your audience."
        },
        "slides_with_issues": {
            "7": {
                "issues": [
                    "Excessive right gazing"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.82,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "no_face": 18.3,
                    "right": 42.0,
                    "center": 39.7
                }
            },
            "8": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "center",
                "valid_gaze_ratio": 0.25,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "right": 6.2,
                    "center": 18.8,
                    "no_face": 75.0
                }
            },
            "12": {
                "issues": [
                    "Excessive right gazing",
                    "Insufficient center gaze"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.92,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "no_face": 8.3,
                    "right": 68.8,
                    "center": 22.9
                }
            },
            "14": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.25,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 75.0,
                    "right": 25.0
                }
            },
            "15": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "no_valid_gaze",
                "valid_gaze_ratio": 0.0,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 100.0
                }
            },
            "17": {
                "issues": [
                    "Excessive right gazing"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.88,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "no_face": 11.5,
                    "right": 46.2,
                    "center": 42.3
                }
            },
            "18": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "center",
                "valid_gaze_ratio": 0.17,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 82.6,
                    "center": 8.7,
                    "right": 8.7
                }
            },
            "20": {
                "issues": [
                    "Excessive right gazing",
                    "Insufficient center gaze"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.76,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "center": 24.5,
                    "right": 51.0,
                    "no_face": 24.5
                }
            },
            "22": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "no_valid_gaze",
                "valid_gaze_ratio": 0.0,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 100.0
                }
            },
            "24": {
                "issues": [
                    "Excessive right gazing",
                    "Insufficient center gaze"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.99,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "center": 23.0,
                    "right": 75.7,
                    "no_face": 1.4
                }
            },
            "25": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "no_valid_gaze",
                "valid_gaze_ratio": 0.0,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 100.0
                }
            },
            "26": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "center",
                "valid_gaze_ratio": 0.29,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 71.4,
                    "center": 28.6
                }
            },
            "30": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "no_valid_gaze",
                "valid_gaze_ratio": 0.0,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 100.0
                }
            },
            "31": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "no_valid_gaze",
                "valid_gaze_ratio": 0.0,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 100.0
                }
            },
            "33": {
                "issues": [
                    "Poor face visibility"
                ],
                "dominant_gaze": "no_valid_gaze",
                "valid_gaze_ratio": 0.0,
                "recommendation": "Face not visible in many frames. Ensure proper camera positioning and lighting.",
                "gaze_distribution": {
                    "no_face": 100.0
                }
            },
            "35": {
                "issues": [
                    "Excessive right gazing",
                    "Insufficient center gaze"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.77,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "center": 18.2,
                    "right": 59.1,
                    "no_face": 22.7
                }
            },
            "36": {
                "issues": [
                    "Excessive right gazing",
                    "Insufficient center gaze"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.8,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "center": 20.0,
                    "right": 60.0,
                    "no_face": 20.0
                }
            },
            "37": {
                "issues": [
                    "Excessive right gazing",
                    "Insufficient center gaze"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 0.74,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "no_face": 26.1,
                    "center": 17.4,
                    "right": 56.5
                }
            },
            "40": {
                "issues": [
                    "Excessive right gazing"
                ],
                "dominant_gaze": "right",
                "valid_gaze_ratio": 1.0,
                "recommendation": "You tend to look right frequently. Try to maintain more centered gaze.",
                "gaze_distribution": {
                    "right": 60.0,
                    "center": 40.0
                }
            }
        }
    },
    "gesture_summary": {
        "head": {
            "valid_frames": 5010,
            "recommendation": "Reduce excessive head movement for a calmer presence."
        },
        "left_shoulder": {
            "valid_frames": 5010,
            "recommendation": "No recommendation available."
        },
        "right_shoulder": {
            "valid_frames": 5010,
            "recommendation": "No recommendation available."
        },
        "left_elbow": {
            "valid_frames": 4151,
            "recommendation": "No recommendation available."
        },
        "right_elbow": {
            "valid_frames": 4216,
            "recommendation": "No recommendation available."
        },
        "left_wrist": {
            "valid_frames": 4114,
            "recommendation": "No recommendation available."
        },
        "right_wrist": {
            "valid_frames": 4091,
            "recommendation": "No recommendation available."
        }
    }
}