import json
import os
import subprocess
import re
from collections import Counter

def generate_llm_analysis(prompt: str, model: str = "mistral", timeout: int = 180) -> str:
    """
    Sends a prompt to a local LLM via the Ollama CLI and returns the text output.

    Args:
        prompt (str): The prompt to send to the model.
        model (str): The name of the Ollama model to use (e.g., "mistral").
        timeout (int): The timeout in seconds for the command.

    Returns:
        str: The text response from the LLM.
    """
    command = ["ollama", "run", model]
    full_prompt = f"Please provide a direct, concise analysis based on the following. Do not include any conversational filler or introductory phrases. Just provide the analysis text itself.\n\n{prompt}"
    
    try:
        result = subprocess.run(
            command,
            input=full_prompt.encode("utf-8"),
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=timeout,
            check=True
        )
        response_text = result.stdout.decode("utf-8").strip()
        return response_text
    except FileNotFoundError:
        error_msg = "Error: The 'ollama' command was not found. Is Ollama installed and in your system's PATH?"
        print(error_msg)
        return error_msg
    except subprocess.CalledProcessError as e:
        error_msg = f"Error: Ollama command failed with error: {e.stderr.decode('utf-8')}"
        print(error_msg)
        return error_msg
    except subprocess.TimeoutExpired:
        error_msg = f"Error: Ollama command timed out after {timeout} seconds."
        print(error_msg)
        return error_msg
    except Exception as e:
        error_msg = f"An unexpected error occurred while querying Ollama: {e}"
        print(error_msg)
        return error_msg

def find_key_issues(data):
    """
    Analyzes the entire dataset to find recurring issues and returns a summary.
    """
    issues = []
    segments = data.get('segments', [])
    
    # Check for text-heavy slides
    text_heavy_slides = [s['slide_id'] for s in segments if s.get('video_word_count', 0) > 100]
    if len(text_heavy_slides) > 2:
        issues.append(f"- Overly Text-Dense Slides: Slides {', '.join(map(str, text_heavy_slides))} are overloaded with text, making them difficult for the audience to read.")

    # Check for gaze issues
    # Corrected line to handle potential None values for 'gaze_recommendation'
    gaze_issues = [s['slide_id'] for s in segments if "gaze" in (s.get('gaze_recommendation') or '').lower() and "excellent" not in (s.get('gaze_recommendation') or '').lower()]
    if len(gaze_issues) > len(segments) * 0.25: # If more than 25% of slides have gaze issues
        issues.append("- Inconsistent Eye Contact: The speaker frequently looks away from the camera, which can disengage the audience.")

    # Check for gesture issues
    gesture_recommendations = []
    for s in segments:
        for joint, details in s.get('gesture_joint_details', {}).items():
            if "excessive" in details.get('recommendation', ''):
                gesture_recommendations.append(joint.replace('_', ' ').title())
    
    if gesture_recommendations:
        most_common_gesture_issue = Counter(gesture_recommendations).most_common(1)[0][0]
        issues.append(f"- Distracting Body Language: There is a pattern of excessive movement, particularly with the {most_common_gesture_issue}, suggesting a need for a more stable posture.")

    # Check for dominant negative emotion
    emotions = [s.get('dominant_emotion') for s in segments if s.get('dominant_emotion')]
    common_emotions = Counter(emotions).most_common(1)
    if common_emotions and common_emotions[0][0] in ["Anger", "Sadness", "Disgust", "Fear"]:
        issues.append(f"- Intense Emotional Tone: The most frequently detected emotion was '{common_emotions[0][0]}'. This may come across as overly intense or negative to the audience.")

    return issues

def analyze_presentation(data):
    """
    Analyzes the presentation data and generates a full text report.
    """
    report = []

    # --- Overall Presentation Analysis ---
    report.append("=======================================")
    report.append("=      Overall Presentation Analysis      =")
    report.append("=======================================\n")

    # --- Key Issues Summary ---
    report.append("--- Key Issues & Recommendations ---")
    key_issues = find_key_issues(data)
    if key_issues:
        report.extend(key_issues)
    else:
        report.append("No major recurring issues were detected. Great job!")
    report.append("\n")

    # LLM-generated Overall Summary
    report.append("--- Narrative Coaching (Generated by Mistral) ---")
    
    # Prepare JSON strings outside of the f-string to prevent syntax errors
    key_issues_json = json.dumps(key_issues, indent=2)
    summary_json = json.dumps(data.get('summary', {}), indent=2)

    overall_prompt = f"""
    You are an executive presentation coach. Based on the following summary data and key detected issues, write a brief, insightful narrative analysis.
    Start by acknowledging a strength, then focus on the 2-3 most critical areas for improvement based on the key issues provided.
    Provide specific, actionable advice for each area.

    Key Issues Detected:
    {key_issues_json}

    Overall Summary Data:
    {summary_json}
    """
    report.append(generate_llm_analysis(overall_prompt) + "\n")

    # --- Detailed Data Breakdown ---
    report.append("--- Detailed Data Breakdown ---\n")
    video_info = data.get('video_info', {})
    report.append(f"Presentation Title: Analysis of '{video_info.get('filename', 'N/A')}'")
    report.append(f"Total Duration: {video_info.get('duration', 0) / 60:.2f} minutes")
    report.append(f"Total Slides: {video_info.get('total_slides', 'N/A')}\n")
    
    summary = data.get('summary', {})
    report.append(f"Average time per slide: {summary.get('average_slide_duration', 0):.2f} seconds")
    report.append(f"Total Filler Words: {summary.get('total_filler_words', 'N/A')}")
    report.append(f"Total Filler Phrases: {summary.get('total_filler_phrases', 'N/A')}\n")

    # --- Per-Slide Analysis ---
    report.append("\n=======================================")
    report.append("=         Per-Slide Analysis          =")
    report.append("=======================================\n")

    for slide in data.get('segments', []):
        report.append(f"--- Slide {slide.get('slide_id')} ---")
        report.append(f"Timestamp: {slide.get('time_formatted', 'N/A')}")
        report.append(f"Duration: {slide.get('duration', 0):.2f} seconds\n")

        report.append(f"  Content Analysis:")
        report.append(f"    - Words on slide: {slide.get('video_word_count', 'N/A')}")
        report.append(f"    - Spoken words: {slide.get('audio_word_count', 'N/A')}")
        
        slide_prompt = f"""
        You are a presentation coach. Analyze the data for slide {slide.get('slide_id')}.
        - Duration: {slide.get('duration', 0):.1f}s
        - Words on slide: {slide.get('video_word_count')}
        - Spoken words: {slide.get('audio_word_count')}
        - Dominant Emotion: {slide.get('dominant_emotion', 'N/A')}

        Identify the SINGLE most important issue for this slide (e.g., word count imbalance, pacing, emotional tone). 
        Provide one brief, concrete sentence of advice to fix it.
        Example: The text on this slide is overwhelming; try replacing it with a single powerful image and a title.
        """
        report.append(f"    - LLM Coaching Tip: {generate_llm_analysis(slide_prompt)}\n")

        report.append(f"  Delivery Cues:")
        report.append(f"    - Dominant Emotion: {slide.get('dominant_emotion', 'N/A')}")
        report.append(f"    - Gaze Recommendation: {slide.get('gaze_recommendation', 'N/A')}")
        report.append("\n" + ("-"*20) + "\n")


    return "\n".join(report)

def main():
    """
    Main function to run the analysis script.
    It automatically finds and uses the first .json file in the directory.
    """
    json_file_path = None
    for file in os.listdir('.'):
        if file.endswith('.json'):
            json_file_path = file
            break

    if not json_file_path:
        print("Error: No JSON analysis file found. Please upload a JSON file to proceed.")
        return

    print(f"Found and analyzing the file: '{json_file_path}'")

    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError:
        print(f"Error: The file '{json_file_path}' is not a valid JSON file.")
        return
    except Exception as e:
        print(f"An error occurred while reading the file: {e}")
        return

    print("\nGenerating analysis... This may take a few moments as it queries the local LLM.")
    report_content = analyze_presentation(data)

    output_filename = "presentation_analysis_report_v2.txt"
    
    try:
        with open(output_filename, 'w', encoding='utf-8') as f:
            f.write(report_content)
        print(f"\nAnalysis complete. Improved report saved to '{output_filename}'")
    except Exception as e:
        print(f"An error occurred while writing the report file: {e}")


if __name__ == "__main__":
    main()
